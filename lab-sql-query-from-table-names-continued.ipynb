{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Get the OpenAI API key from environment variables\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set the OpenAI API key in the OpenAI Python package\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    " CREATE SEVERAL (3+) TABLES HERE\n",
    "\"\"\"} ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
    "WRITE IN YOUR CONTEXT QUERIES HERE\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load your .env file (optional, if you're using an environment file to store keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')  # Or directly input the key: 'your-api-key-here'\n",
    "\n",
    "# Sample function to use OpenAI\n",
    "def get_sql_response(user_message):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a SQL assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something that can be solved with SQL, please.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role': 'user', 'content': \"question: \" + user_message})\n",
    "    \n",
    "    # Generate the response\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=newcontext,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Example usage\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with 'This is your SQL,' and after that an SQL that can do what the user requested. Your Database is composed of a SQL database with some tables. Try to maintain the SQL order simple. Put the SQL command in white letters with a black background, and just after a simple and concise text explaining how it works. If the user asks for something that cannot be solved with SQL, just answer something nice and simple, maximum 10 words, asking for something that can be solved with SQL.\n",
    "\"\"\", old_context_user))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see that you haven't provided any tables or specific questions to answer. Please provide the tables and questions you would like me to use for the queries.\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL: \n",
      "\n",
      "```sql\n",
      "SELECT * FROM employees;\n",
      "```\n",
      "\n",
      "Explanation: This SQL query selects all data from the \"employees\" table.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a091918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM employees WHERE ID_usr = 1;\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Prompt 1: Basic Setup\n",
    "Start by defining the structure and the behavior of the bot. This includes setting up a database, creating SQL commands, and making sure the responses are in a simple format. \"\"\"\n",
    "# Basic Setup: Define the database and SQL command structure\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    new_context = context.copy()\n",
    "    new_context.append({'role': 'user', 'content': user_message})\n",
    "    \n",
    "    # Sample SQL database schema\n",
    "    tables = {\n",
    "        'employees': {'ID_usr': 'int', 'name': 'varchar'},\n",
    "        'salary': {'ID_usr': 'int', 'year': 'date', 'salary': 'float'}\n",
    "    }\n",
    "    \n",
    "    # Placeholder SQL query construction (to be replaced in later prompts)\n",
    "    query = f\"SELECT * FROM {list(tables.keys())[0]} WHERE ID_usr = 1;\"\n",
    "    \n",
    "    return query  # Returning a simple query as a placeholder\n",
    "\n",
    "# Initial prompt\n",
    "old_context_user = [{\"role\": \"system\", \"content\": \"You are an SQL assistant.\"}]\n",
    "print(return_CCRMSQL(\"Show me all employees.\", old_context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144a2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        SELECT employees.name, salary.salary\n",
      "        FROM employees\n",
      "        JOIN salary ON employees.ID_usr = salary.ID_usr\n",
      "        WHERE salary.salary > 50000 AND salary.year = '2023';\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Prompt 2: Expanding Functionality\n",
    "Here, we enhance the bot's ability to generate more complex SQL queries based on user inputs, including JOIN operations and conditi \"\"\"\n",
    "# Expanding SQL query functionality\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    new_context = context.copy()\n",
    "    new_context.append({'role': 'user', 'content': user_message})\n",
    "\n",
    "    # Extracting action from user_message\n",
    "    if \"employees with salary\" in user_message:\n",
    "        query = \"\"\"\n",
    "        SELECT employees.name, salary.salary\n",
    "        FROM employees\n",
    "        JOIN salary ON employees.ID_usr = salary.ID_usr\n",
    "        WHERE salary.salary > 50000 AND salary.year = '2023';\n",
    "        \"\"\"\n",
    "    else:\n",
    "        query = \"SELECT * FROM employees;\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "# Prompt with more complexity\n",
    "old_context_user = [{\"role\": \"system\", \"content\": \"You are an SQL assistant.\"}]\n",
    "print(return_CCRMSQL(\"Get employees with salary over 50000 in 2023.\", old_context_user))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72f5b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This request cannot be solved with SQL.\n",
      "Please ask something solvable with SQL, like querying data from tables.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Prompt 3: Adding Explanation and Error Handling\n",
    "Now, we add explanations for the generated SQL and handle scenarios where the request cannot be solved with SQL. \"\"\"\n",
    "# Adding explanations and handling unsolvable SQL requests\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    new_context = context.copy()\n",
    "    new_context.append({'role': 'user', 'content': user_message})\n",
    "\n",
    "    # Check for specific conditions in the message\n",
    "    if \"employees with salary\" in user_message:\n",
    "        query = \"\"\"\n",
    "        SELECT employees.name, salary.salary\n",
    "        FROM employees\n",
    "        JOIN salary ON employees.ID_usr = salary.ID_usr\n",
    "        WHERE salary.salary > 50000 AND salary.year = '2023';\n",
    "        \"\"\"\n",
    "        explanation = \"This SQL query retrieves the names and salaries of employees who earned more than 50,000 in 2023.\"\n",
    "    else:\n",
    "        query = \"This request cannot be solved with SQL.\"\n",
    "        explanation = \"Please ask something solvable with SQL, like querying data from tables.\"\n",
    "    \n",
    "    return query, explanation\n",
    "\n",
    "# Final prompt with explanation\n",
    "old_context_user = [{\"role\": \"system\", \"content\": \"You are an SQL assistant.\"}]\n",
    "query, explanation = return_CCRMSQL(\"Show all employees who received a bonus.\", old_context_user)\n",
    "print(query)\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f420e83",
   "metadata": {},
   "source": [
    "Summary:\n",
    "Prompt 1 defines a basic SQL structure.\n",
    "Prompt 2 introduces more complex SQL generation, including conditions.\n",
    "Prompt 3 adds explanations and error handling to guide the user."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
