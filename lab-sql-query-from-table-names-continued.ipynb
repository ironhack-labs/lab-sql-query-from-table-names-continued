{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7092da94",
   "metadata": {},
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db405e",
   "metadata": {},
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2600f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd86e19",
   "metadata": {},
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd585527",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "CREATE TABLE employees (\n",
    "  ID_usr INT,\n",
    "  name VARCHAR(100)\n",
    ");\n",
    "\n",
    "INSERT INTO employees (ID_usr, name) VALUES\n",
    "(1, 'John Doe'),\n",
    "(2, 'Jane Smith'),\n",
    "(3, 'Alice Johnson');\n",
    "\n",
    "CREATE TABLE salary (\n",
    "  ID_usr INT,\n",
    "  year DATE,\n",
    "  salary FLOAT\n",
    ");\n",
    "\n",
    "INSERT INTO salary (ID_usr, year, salary) VALUES\n",
    "(1, '2022-01-01', 50000),\n",
    "(2, '2022-01-01', 60000),\n",
    "(3, '2022-01-01', 55000);\n",
    "\n",
    "CREATE TABLE studies (\n",
    "  ID INT,\n",
    "  ID_usr INT,\n",
    "  educational_level INT,\n",
    "  Institution VARCHAR(100),\n",
    "  Years DATE,\n",
    "  Speciality VARCHAR(100)\n",
    ");\n",
    "\n",
    "INSERT INTO studies (ID, ID_usr, educational_level, Institution, Years, Speciality) VALUES\n",
    "(1, 1, 5, 'MIT', '2019-05-12', 'Computer Science'),\n",
    "(2, 2, 4, 'Stanford', '2018-05-15', 'Mechanical Engineering'),\n",
    "(3, 3, 6, 'Harvard', '2017-05-10', 'Biology');\n",
    "\"\"\"} ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1acd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    "-- Get the names of all employees.\n",
    "SELECT name FROM employees;\n",
    "\n",
    "-- Get the total salary of all employees for the year 2022.\n",
    "SELECT SUM(salary) FROM salary WHERE year = '2022-01-01';\n",
    "\n",
    "-- Get the educational institution and speciality for a specific user.\n",
    "SELECT Institution, Speciality FROM studies WHERE ID_usr = 1;\n",
    "\"\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c188917",
   "metadata": {},
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3e94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT name FROM employees;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "#1 . Query for Employee Names\n",
    "# Weâ€™ll ask the model to retrieve all employee names.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Retrieve all employee names\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT name FROM employees;\n",
      "```\n",
      "This SQL command selects all the names from the \"employees\" table, retrieving all employee names.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"Retrieve all employee names\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d9308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total salary paid in 2022 is $165,000.\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "# 2. Query for Total Salary in 2022\n",
    "# Weâ€™ll ask for the total salary paid to employees in 2022.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"What is the total salary paid in 2022?\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e5865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT SUM(salary) AS total_salary_paid\n",
      "FROM salary\n",
      "WHERE year = '2022';\n",
      "```\n",
      "\n",
      "This SQL query selects the sum of the salaries paid in the year 2022 from the \"salary\" table.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"What is the total salary paid in 2022?\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309daa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The institution and speciality for employee ID 1 are as follows:\n",
      "- Institution: MIT\n",
      "- Speciality: Computer Science\n"
     ]
    }
   ],
   "source": [
    "# New\n",
    "# 3. Query for Institution and Speciality\n",
    "# Weâ€™ll ask for the institution and speciality of a specific employee.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"What is the institution and speciality for employee ID 1?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT Institution, Speciality\n",
      "FROM studies\n",
      "WHERE ID_usr = 1;\n",
      "```\n",
      "\n",
      "This SQL query selects the institution and speciality for the employee with ID 1 from the \"studies\" table.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"What is the institution and speciality for employee ID 1?\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a6419",
   "metadata": {},
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf22ec",
   "metadata": {},
   "source": [
    "In this experiment i tested GPT-3.5â€™s ability to write SQL queries using two different prompts. The old prompt had basic table descriptions and no examples, while the new prompt gave more detailed instructions, showing the table structure and example queries.\n",
    "\n",
    "With the new prompt, the model gave more accurate results, understanding how to connect the tables correctly. It also wrote simpler and clearer SQL queries, while the old prompt sometimes created confusing or too complicated queries. In tricky cases, like difficult queries, the new prompt did better at either solving the problem or explaining why it couldnâ€™t. The old prompt sometimes made mistakes or added tables that didnâ€™t exist.\n",
    "\n",
    "This experiment showed how important it is to give clear and detailed prompts. When the model had better instructions and examples, it made fewer mistakes. Using examples (few-shot learning) really helped the model produce accurate and easy-to-read SQL.\n",
    "\n",
    "In the end, the new prompt with better explanations and examples made the modelâ€™s SQL queries much more reliable than the old version, showing how well-designed prompts can improve results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
