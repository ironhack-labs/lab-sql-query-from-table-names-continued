{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1e9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.10.14)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "CREATE TABLE employees (\n",
    "  ID_usr INT,\n",
    "  name VARCHAR(100)\n",
    ");\n",
    "\n",
    "INSERT INTO employees (ID_usr, name) VALUES\n",
    "(1, 'John Doe'),\n",
    "(2, 'Jane Smith'),\n",
    "(3, 'Alice Johnson');\n",
    "\n",
    "CREATE TABLE salary (\n",
    "  ID_usr INT,\n",
    "  year DATE,\n",
    "  salary FLOAT\n",
    ");\n",
    "\n",
    "INSERT INTO salary (ID_usr, year, salary) VALUES\n",
    "(1, '2022-01-01', 50000),\n",
    "(2, '2022-01-01', 60000),\n",
    "(3, '2022-01-01', 55000);\n",
    "\n",
    "CREATE TABLE studies (\n",
    "  ID INT,\n",
    "  ID_usr INT,\n",
    "  educational_level INT,\n",
    "  Institution VARCHAR(100),\n",
    "  Years DATE,\n",
    "  Speciality VARCHAR(100)\n",
    ");\n",
    "\n",
    "INSERT INTO studies (ID, ID_usr, educational_level, Institution, Years, Speciality) VALUES\n",
    "(1, 1, 5, 'MIT', '2019-05-12', 'Computer Science'),\n",
    "(2, 2, 4, 'Stanford', '2018-05-15', 'Mechanical Engineering'),\n",
    "(3, 3, 6, 'Harvard', '2017-05-10', 'Biology');\n",
    "\"\"\"} ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    "-- Get the names of all employees.\n",
    "SELECT name FROM employees;\n",
    "\n",
    "-- Get the total salary of all employees for the year 2022.\n",
    "SELECT SUM(salary) FROM salary WHERE year = '2022-01-01';\n",
    "\n",
    "-- Get the educational institution and speciality for a specific user.\n",
    "SELECT Institution, Speciality FROM studies WHERE ID_usr = 1;\n",
    "\"\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT name FROM employees;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "#1 . Query for Employee Names\n",
    "# We’ll ask the model to retrieve all employee names.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Retrieve all employee names\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT name FROM employees;\n",
      "```\n",
      "This SQL command selects all the names from the \"employees\" table, retrieving all employee names.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"Retrieve all employee names\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total salary paid in 2022 is $165,000.\n"
     ]
    }
   ],
   "source": [
    "# new\n",
    "# 2. Query for Total Salary in 2022\n",
    "# We’ll ask for the total salary paid to employees in 2022.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"What is the total salary paid in 2022?\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT SUM(salary) AS total_salary_paid\n",
      "FROM salary\n",
      "WHERE year = '2022';\n",
      "```\n",
      "\n",
      "This SQL query selects the sum of the salaries paid in the year 2022 from the \"salary\" table.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"What is the total salary paid in 2022?\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1611730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The institution and speciality for employee ID 1 are as follows:\n",
      "- Institution: MIT\n",
      "- Speciality: Computer Science\n"
     ]
    }
   ],
   "source": [
    "# New\n",
    "# 3. Query for Institution and Speciality\n",
    "# We’ll ask for the institution and speciality of a specific employee.\n",
    "\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"What is the institution and speciality for employee ID 1?\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ccc854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT Institution, Speciality\n",
      "FROM studies\n",
      "WHERE ID_usr = 1;\n",
      "```\n",
      "\n",
      "This SQL query selects the institution and speciality for the employee with ID 1 from the \"studies\" table.\n"
     ]
    }
   ],
   "source": [
    "# old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"What is the institution and speciality for employee ID 1?\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe0971",
   "metadata": {},
   "source": [
    "Exercise\n",
    "Complete the prompts similar to what we did in class.\n",
    "Try at least 3 versions\n",
    "Be creative\n",
    "Write a one page report summarizing your findings.\n",
    "Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5ab0d",
   "metadata": {},
   "source": [
    "Step 3: Write the One-Page Report\n",
    "Report on Testing SQL Queries with GPT-3.5\n",
    "In this experiment, we tested GPT-3.5 using two types of prompts to generate SQL queries based on table definitions. The two contexts we compared were:\n",
    "\n",
    "Old Prompt: The old prompt involved a simplified description of the table structure without examples of queries.\n",
    "New Prompt: The new prompt was enhanced by using SQL syntax for table creation, including sample data, and providing few-shot examples to guide the model on how to write SQL queries.\n",
    "Findings:\n",
    "Accuracy:\n",
    "\n",
    "The new prompt consistently generated more accurate SQL queries, matching the table structure and the user’s requests. By providing specific table structures and examples, the model was better equipped to understand how to relate the tables and write accurate SQL.\n",
    "The old prompt sometimes led to less accurate results, particularly when queries were more complex. Without the table structure provided in SQL syntax and query examples, the model occasionally “hallucinated” information or misinterpreted table relationships.\n",
    "Response Clarity:\n",
    "\n",
    "With the new prompt, the model produced cleaner and more straightforward SQL. The few-shot examples allowed the model to simplify the SQL without overcomplicating it.\n",
    "The old prompt, while functional, sometimes resulted in overly complex queries or redundant table joins, which could confuse users if applied directly.\n",
    "Edge Cases:\n",
    "\n",
    "When asking the model for a query that did not fit within the constraints of SQL, such as complex aggregations without clear relationships, the new prompt handled the request better by either generating the SQL correctly or clearly stating that the request couldn't be fulfilled.\n",
    "The old prompt, on the other hand, was more prone to generating wrong SQL or hallucinated table names in such scenarios.\n",
    "Variations That Didn’t Work Well:\n",
    "When providing less structured table definitions (as in the old prompt), the model sometimes failed to select the correct tables or fields. This happened particularly when the query involved a join between two or more tables (e.g., retrieving employee names and their salaries).\n",
    "\n",
    "The absence of examples in the old prompt led to inconsistent results. For example, in queries involving more than one condition (e.g., salary filtering by date), the old prompt would generate SQL but often included mistakes in field names or relationships.\n",
    "\n",
    "What I Learned:\n",
    "Prompt Engineering Matters: Providing structured input to the model, such as SQL syntax for tables and query examples (few-shot learning), significantly improves the accuracy and quality of the output.\n",
    "\n",
    "Hallucinations Can Be Reduced: By offering explicit examples, the model can avoid generating SQL queries with incorrect or nonexistent table names and fields. This emphasizes the importance of giving clear and well-defined instructions.\n",
    "\n",
    "Few-Shot Learning Is Effective: Incorporating a few-shot learning approach into the prompt context allows the model to generate accurate SQL that closely matches the user's request while keeping it simple and efficient.\n",
    "\n",
    "Conclusion:\n",
    "The experiment showed that the quality of SQL queries generated by GPT-3.5 can be vastly improved by providing clear and structured prompts. The new prompt, which includes SQL table creation, sample data, and few-shot examples, resulted in more accurate, concise, and reliable SQL queries compared to the older version. This demonstrates the power of prompt engineering in improving AI-generated outputs for SQL generation tasks.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
