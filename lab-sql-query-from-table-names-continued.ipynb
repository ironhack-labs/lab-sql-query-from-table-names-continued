{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "#NOTE: Identation is not very important here because SQL does not rely on proper Identation\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "-- Table: employees\n",
    "CREATE TABLE employees (\n",
    "    ID_usr INT,\n",
    "    name VARCHAR(100),\n",
    "    age INT\n",
    ");\n",
    "-- Sample Rows:\n",
    "INSERT INTO employees (ID_usr, name, age) VALUES (1, 'Alice', 30);\n",
    "INSERT INTO employees (ID_usr, name, age) VALUES (2, 'Bob', 45);\n",
    "\n",
    "-- Table: salary\n",
    "CREATE TABLE salary (\n",
    "    ID_usr INT,\n",
    "    year DATE,\n",
    "    salary FLOAT\n",
    ");\n",
    "-- Sample Rows:\n",
    "INSERT INTO salary (ID_usr, year, salary) VALUES (1, '2020-01-01', 50000);\n",
    "INSERT INTO salary (ID_usr, year, salary) VALUES (2, '2020-01-01', 70000);\n",
    "\n",
    "-- Table: studies\n",
    "CREATE TABLE studies (\n",
    "    ID INT,\n",
    "    ID_usr INT,\n",
    "    educational_level INT,\n",
    "    institution VARCHAR(100),\n",
    "    years DATE,\n",
    "    speciality VARCHAR(100)\n",
    ");\n",
    "-- Sample Rows:\n",
    "INSERT INTO studies (ID, ID_usr, educational_level, institution, years, speciality) \n",
    "VALUES (1, 1, 5, 'Harvard', '2015-01-01', 'Computer Science');\n",
    "INSERT INTO studies (ID, ID_usr, educational_level, institution, years, speciality) \n",
    "VALUES (2, 2, 7, 'Stanford', '2010-01-01', 'Engineering');\n",
    "\"\"\" } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "#FEW SHOT SAMPLES\n",
    "context.append( {'role':'system', 'content':\"\"\"\n",
    "-- Example Query 1:\n",
    "-- Retrieve the name and salary of employees who earn more than 60,000.\n",
    "SELECT e.name, s.salary\n",
    "FROM employees e\n",
    "JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "WHERE s.salary > 60000;\n",
    "\n",
    "-- Example Query 2:\n",
    "-- Retrieve employees who studied at 'Harvard'.\n",
    "SELECT e.name\n",
    "FROM employees e\n",
    "JOIN studies st ON e.ID_usr = st.ID_usr\n",
    "WHERE st.institution = 'Harvard';\n",
    "\n",
    "-- Example Query 3:\n",
    "-- Retrieve the educational level of employees who have a salary greater than 50,000.\n",
    "SELECT e.name, st.educational_level\n",
    "FROM employees e\n",
    "JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "JOIN studies st ON e.ID_usr = st.ID_usr\n",
    "WHERE s.salary > 50000;\n",
    "\"\"\" } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_Usr = s.ID_Usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"YOUR QUERY HERE\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT e.name\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query retrieves the name of the employee who is best paid by joining the \"employees\" table with the \"salary\" table on the ID_usr field. It then orders the result by salary in descending order and limits the output to only one row, which corresponds to the employee with the highest salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"Retruve the name and salary of employees who earn less than 40,000\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT st.Institution, AVG(sa.salary) AS avg_salary\n",
      "FROM studies st\n",
      "JOIN employees e ON st.ID_Usr = e.ID_Usr\n",
      "JOIN salary sa ON e.ID_Usr = sa.ID_Usr\n",
      "GROUP BY st.Institution\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"Retrieve the names and salaries of employees who earn more than 40,000\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "SELECT s.Institution\n",
      "FROM studies s\n",
      "JOIN salary sa ON s.ID_usr = sa.ID_usr\n",
      "GROUP BY s.Institution\n",
      "ORDER BY AVG(sa.salary) DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "This SQL query joins the \"studies\" and \"salary\" tables on the ID_usr column. It then calculates the average salary for each institution, orders the results in descending order based on the average salary, and returns the institution with the highest average salary.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"What is the salary of the youngest employee?\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8159425",
   "metadata": {},
   "source": [
    "As proof of concept the ChatGPT was able to retrive the SQL inforamtion of the names and users that were requested.\n",
    "The Chat refuse to give wrong information if not avaiable but it was succesfull in avoiding Hallucinations by giving wrong queries that were out of bound of the SQL data set.\n",
    "\n",
    "The speed and precision of the Chat was great to obtain releyable information of the data base.\n",
    "\n",
    "The small and consise Prompts gives the best results, the long prompts are not giving better results just redundant and makes the chat output the same info.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662960e",
   "metadata": {},
   "source": [
    "Improved by just keeping the prompt shot.\n",
    "Long promtps are just a waist of tokens.\n",
    "Long prompts can cause hallucinations and spit out wrong information or break the result resulting on a error or a wrong result.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
