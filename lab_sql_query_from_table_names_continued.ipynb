{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "id": "bbxk3saioOnJ",
        "outputId": "769f63fb-5ddc-4b90-93d6-cb7c6fd47eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bbxk3saioOnJ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
      "metadata": {
        "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
      },
      "source": [
        "# SQL query from table names - Continued"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a03f026a",
      "metadata": {
        "id": "a03f026a"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY  = userdata.get('OPENAI_API_KEY')\n",
        "#OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "bOxVuwCnycdy",
        "outputId": "1c7d2891-ef21-4b42-d88f-8fda81003fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bOxVuwCnycdy",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
      "metadata": {
        "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
      },
      "source": [
        "## The old Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "922f8d24",
      "metadata": {
        "id": "922f8d24"
      },
      "outputs": [],
      "source": [
        "#The old prompt\n",
        "old_context = [ {'role':'system', 'content':\"\"\"\n",
        "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
        "this is your SQL, and after that an SQL that can do what the user request. \\\n",
        "Your Database is composed by a SQL database with some tables. \\\n",
        "Try to maintain the SQL order simple.\n",
        "Put the SQL command in white letters with a black background, and just after \\\n",
        "a simple and concise text explaining how it works.\n",
        "If the user ask for something that can not be solved with an SQL Order \\\n",
        "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
        "can be solved with SQL.\n",
        "\"\"\"} ]\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "first table:\n",
        "{\n",
        "  \"tableName\": \"employees\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"tipo\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"nombre\": \"name\",\n",
        "      \"tipo\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "second table:\n",
        "{\n",
        "  \"tableName\": \"salary\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"year\",\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"salary\",\n",
        "      \"type\": \"float\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "third table:\n",
        "{\n",
        "  \"tablename\": \"studies\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"name\": \"ID\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"educational_level\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Institution\",\n",
        "      \"type\": \"varchar\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Years\",\n",
        "      \"type\": \"date\"\n",
        "    }\n",
        "    {\n",
        "      \"name\": \"Speciality\",\n",
        "      \"type\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
      "metadata": {
        "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
      },
      "source": [
        "## New Prompt.\n",
        "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
        "\n",
        "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
        "\n",
        "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5334f942",
      "metadata": {
        "id": "5334f942"
      },
      "outputs": [],
      "source": [
        "context = [ {'role':'system', 'content':\"\"\"\n",
        " CREATE SEVERAL (3+) TABLES HERE\n",
        "\"\"\"} ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
      "metadata": {
        "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
      },
      "outputs": [],
      "source": [
        "#FEW SHOT SAMPLES\n",
        "context.append( {'role':'system', 'content':\"\"\"\n",
        " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
        "WRITE IN YOUR CONTEXT QUERIES HERE\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b90f417a",
      "metadata": {
        "id": "b90f417a"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_CCRMSQL(user_message, context):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n",
        "    newcontext = context.copy()\n",
        "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=newcontext,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
      "metadata": {
        "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
      },
      "source": [
        "## NL2SQL Samples\n",
        "We're going to review some examples generated with the old prompt and others with the new prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "59e8202c-ce34-487e-9037-c65a263423ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59e8202c-ce34-487e-9037-c65a263423ed",
        "outputId": "d0df6a48-bb78-47df-9e4e-b18ad6280f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine who makes the most money, we need to have a table that includes information about the employees and their salaries. Let's create a table named \"employees\" with columns for employee ID, name, and salary.\n",
            "\n",
            "```sql\n",
            "CREATE TABLE employees (\n",
            "    employee_id INT PRIMARY KEY,\n",
            "    name TEXT,\n",
            "    salary DECIMAL\n",
            ");\n",
            "```\n",
            "\n",
            "Next, we need to populate this table with some sample data to run a query to find out who makes the most money.\n",
            "\n",
            "```sql\n",
            "INSERT INTO employees (employee_id, name, salary) VALUES (1, 'Alice', 60000);\n",
            "INSERT INTO employees (employee_id, name, salary) VALUES (2, 'Bob', 75000);\n",
            "INSERT INTO employees (employee_id, name, salary) VALUES (3, 'Charlie', 90000);\n",
            "INSERT INTO employees (employee_id, name, salary) VALUES (4, 'David', 80000);\n",
            "```\n",
            "\n",
            "Now, to find out who makes the most money, we can run the following query:\n",
            "\n",
            "```sql\n",
            "SELECT name, salary\n",
            "FROM employees\n",
            "ORDER BY salary DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "\n",
            "This query will return the employee who makes the most money along with their salary.\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "context_user = context.copy()\n",
        "print(return_CCRMSQL(\"WHO MAKES THE MOST MONEY!\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
        "outputId": "7c8da36c-b9c5-4c42-a5fb-36203d20df05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT name\n",
            "FROM employees\n",
            "ORDER BY ID_usr DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "\n",
            "This SQL query selects the name of the employee with the highest ID_usr, which could be interpreted as the \"best\" employee. It orders the employees in descending order based on their ID_usr and then limits the result to only the top row, which corresponds to the employee with the highest ID_usr.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "old_context_user = old_context.copy()\n",
        "print(return_CCRMSQL(\"Who is the best employee?\", old_context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
        "outputId": "3eb9a9b6-61b2-4e7f-d8a3-d2b075fd367a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT institution_name\n",
            "FROM employees\n",
            "WHERE employee_id IN (\n",
            "    SELECT employee_id\n",
            "    FROM performance\n",
            "    ORDER BY rating DESC\n",
            "    LIMIT 1\n",
            ");\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"From which institution are our best employees?\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
        "outputId": "36443364-1413-4a21-d08b-30752622150b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT Institution, COUNT(*) AS Recruit_Count\n",
            "FROM studies\n",
            "GROUP BY Institution\n",
            "ORDER BY Recruit_Count DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "\n",
            "This SQL query selects the institution from the `studies` table that recruited the most employees. It counts the number of employees recruited from each institution, orders the results in descending order, and limits the output to show only the institution that recruited the most employees.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"From which institution we recreut the most?\", old_context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
      "metadata": {
        "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
        "     - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version #1"
      ],
      "metadata": {
        "id": "gs9ncRAX5PBW"
      },
      "id": "gs9ncRAX5PBW"
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"What is the name of the employee with the highest salary?\", context_user))"
      ],
      "metadata": {
        "id": "twk19_QP5NQ2",
        "outputId": "6210b271-e76b-444d-8517-5d6e9539b89e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "twk19_QP5NQ2",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT name\n",
            "FROM employees\n",
            "ORDER BY salary DESC\n",
            "LIMIT 1;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"What is the name of the employee with the highest salary?\", old_context_user))"
      ],
      "metadata": {
        "id": "xd0MK63x5WPI",
        "outputId": "fd353912-740e-4f3f-b630-c3395c550f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xd0MK63x5WPI",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT e.name\n",
            "FROM employees e\n",
            "JOIN salary s ON e.ID_usr = s.ID_usr\n",
            "ORDER BY s.salary DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "\n",
            "This SQL query selects the name of the employee with the highest salary by joining the \"employees\" table with the \"salary\" table on the employee ID. It then orders the result by salary in descending order and limits the output to only the top result, which corresponds to the employee with the highest salary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version #2"
      ],
      "metadata": {
        "id": "wq51txce5jPH"
      },
      "id": "wq51txce5jPH"
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"Which institution has the highest average salary for employees with a PhD?\", context_user))"
      ],
      "metadata": {
        "id": "TTw-09FI5YnW",
        "outputId": "e397a281-eee7-4ad6-8d52-08c9d704a672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TTw-09FI5YnW",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT institution_name, AVG(salary) AS avg_salary\n",
            "FROM employees\n",
            "WHERE education = 'PhD'\n",
            "GROUP BY institution_name\n",
            "ORDER BY avg_salary DESC\n",
            "LIMIT 1;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"Which institution has the highest average salary for employees with a PhD?\", old_context_user))"
      ],
      "metadata": {
        "id": "V8PFQosB5q7f",
        "outputId": "50ad1445-e989-4d8a-a8a8-60009a1307ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "V8PFQosB5q7f",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT s.Institution, AVG(sa.salary) AS avg_salary\n",
            "FROM employees e\n",
            "JOIN studies st ON e.ID_usr = st.ID_usr\n",
            "JOIN salary sa ON e.ID_usr = sa.ID_usr\n",
            "WHERE st.educational_level = 'PhD'\n",
            "GROUP BY s.Institution\n",
            "ORDER BY avg_salary DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "\n",
            "This SQL query retrieves the institution with the highest average salary for employees who have a PhD. It joins the tables employees, studies, and salary, filters by employees with a PhD, calculates the average salary per institution, orders the results by average salary in descending order, and limits the output to the top result.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# version #3"
      ],
      "metadata": {
        "id": "H0PnWC6O5vkW"
      },
      "id": "H0PnWC6O5vkW"
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"What is the total salary of employees hired after 2015 who have a master's degree from 'MIT'?\", context_user))"
      ],
      "metadata": {
        "id": "nYYkG7pN5tl3",
        "outputId": "7aaa1cbe-a954-472b-92fd-2d4cbd695e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nYYkG7pN5tl3",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT SUM(salary) AS total_salary\n",
            "FROM employees\n",
            "WHERE hire_date > '2015-01-01'\n",
            "AND education = 'Master\\'s Degree'\n",
            "AND university = 'MIT';\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"What is the total salary of employees hired after 2015 who have a master's degree from 'MIT'?\", old_context_user))"
      ],
      "metadata": {
        "id": "R1OZJ60N7cju",
        "outputId": "536d6407-86af-46b9-c9b8-dcf6c0f3b16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "R1OZJ60N7cju",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT SUM(s.salary) AS total_salary\n",
            "FROM employees e\n",
            "JOIN salary s ON e.ID_usr = s.ID_usr\n",
            "JOIN studies st ON e.ID_usr = st.ID_usr\n",
            "WHERE YEAR(s.year) > 2015\n",
            "AND st.educational_level = 'Master'\n",
            "AND st.Institution = 'MIT';\n",
            "```\n",
            "\n",
            "This SQL query retrieves the total salary of employees hired after 2015 who have a master's degree from 'MIT'. It joins the employees, salary, and studies tables on the employee ID, filters the data for employees hired after 2015 with a master's degree from 'MIT', and calculates the sum of their salaries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version #4"
      ],
      "metadata": {
        "id": "aD_d2r2T7vtO"
      },
      "id": "aD_d2r2T7vtO"
    },
    {
      "cell_type": "code",
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"Which employees hired after 2010, who work in departments with at least 5 employees, have an average salary above $70,000, and obtained their highest degree from institutions ranked in the top 10 globally?\", context_user))"
      ],
      "metadata": {
        "id": "XyFMss-97tt5",
        "outputId": "0a2d56f2-859e-42ed-f4e3-5673e76b0cba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XyFMss-97tt5",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "CREATE TABLE Employees (\n",
            "    employee_id INT PRIMARY KEY,\n",
            "    employee_name VARCHAR(50),\n",
            "    hire_date DATE,\n",
            "    department_id INT,\n",
            "    salary DECIMAL(10, 2),\n",
            "    highest_degree VARCHAR(50)\n",
            ");\n",
            "\n",
            "CREATE TABLE Departments (\n",
            "    department_id INT PRIMARY KEY,\n",
            "    department_name VARCHAR(50),\n",
            "    number_of_employees INT\n",
            ");\n",
            "\n",
            "CREATE TABLE Institutions (\n",
            "    institution_id INT PRIMARY KEY,\n",
            "    institution_name VARCHAR(50),\n",
            "    global_ranking INT\n",
            ");\n",
            "```\n",
            "\n",
            "```sql\n",
            "SELECT e.employee_name\n",
            "FROM Employees e\n",
            "JOIN Departments d ON e.department_id = d.department_id\n",
            "JOIN Institutions i ON e.highest_degree = i.institution_name\n",
            "WHERE e.hire_date > '2010-01-01'\n",
            "AND d.number_of_employees >= 5\n",
            "AND e.salary > 70000\n",
            "AND i.global_ranking <= 10;\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"Which employees hired after 2010, who work in departments with at least 5 employees, have an average salary above $70,000, and obtained their highest degree from institutions ranked in the top 10 globally?\", old_context_user))"
      ],
      "metadata": {
        "id": "D-Flu_yT7z6e",
        "outputId": "d84fcc0f-98ea-437a-8dba-a966c71c9bf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D-Flu_yT7z6e",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "SELECT e.name\n",
            "FROM employees e\n",
            "JOIN salary s ON e.ID_usr = s.ID_usr\n",
            "JOIN studies st ON e.ID_usr = st.ID_usr\n",
            "WHERE YEAR(s.year) > 2010\n",
            "GROUP BY e.name\n",
            "HAVING AVG(s.salary) > 70000\n",
            "```\n",
            "\n",
            "This SQL query selects the names of employees who were hired after 2010, have an average salary above $70,000, and obtained their highest degree from institutions ranked in the top 10 globally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating GPT-3.5-turbo for NL2SQL\n",
        "\n",
        "This report summarizes the performance of GPT-3.5-turbo in converting natural language queries into SQL, comparing two different prompting techniques.  The first (\"old prompt\") provides table schemas in JSON format. The second (\"new prompt\") utilizes SQL CREATE TABLE statements and sample data, augmented with few-shot learning examples.\n",
        "\n",
        "**Methodology:**\n",
        "\n",
        "Four natural language queries of varying complexity were tested against both prompt methods. The queries ranged from simple employee identification to complex filtering involving multiple table joins and aggregations.  The evaluation focused on the accuracy of the generated SQL and the overall effectiveness of each prompt in guiding the model.\n",
        "\n",
        "\n",
        "**Findings:**\n",
        "\n",
        "The \"new prompt\" consistently outperformed the \"old prompt\".  While the \"old prompt\" produced some functional SQL for simpler queries, it frequently failed to correctly interpret complex queries or relations between multiple tables, sometimes completely hallucinating syntax or failing to correctly join the tables required. The provided table schemas in JSON format were not effective.\n",
        "\n",
        "The \"new prompt,\" by employing SQL create table commands and incorporating few-shot learning examples, provided a much clearer context for GPT-3.5-turbo. The model demonstrated improved accuracy and a greater capacity to correctly translate complex natural language instructions into valid SQL.\n",
        "\n",
        "**Hallucinations and Errors:**\n",
        "\n",
        "Several instances of hallucinations and inaccuracies were observed with the old prompt, particularly when queries involved joins or aggregation functions. The model frequently created invalid SQL, missing crucial join conditions, or generating erroneous aggregate functions. It appeared to struggle with the JSON table schemas. The new prompt had fewer errors and mostly minor ones.\n",
        "\n",
        "**Key Learnings:**\n",
        "\n",
        "* **Prompt Engineering is Crucial:**  The performance of the language model is highly sensitive to the prompt.  The inclusion of relevant context, clear instructions, and few-shot examples proved critical for generating accurate SQL.\n",
        "* **Schema Representation Matters:** Representing table schemas using SQL CREATE TABLE commands and sample data provides a more effective context for the model than JSON structures.\n",
        "* **Few-Shot Learning is Beneficial:** Providing the model with a small set of example queries and their corresponding SQL greatly enhanced its ability to generalize to new queries.\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "For generating SQL queries from natural language, using prompts which specify schemas in SQL and employing few-shot learning is highly recommended. Further enhancements could involve providing even more diverse few-shot examples, tailoring the examples to the specific complexity of the target queries, or incorporating table relationships directly into the prompt.\n",
        "\n",
        "\n",
        "**Example Results (abridged):**\n",
        "\n",
        "*(Note: Full results, including the generated SQL from both methods for all four queries, are included in the original Colab notebook.)*\n",
        "\n",
        "* **Query:** \"What is the name of the employee with the highest salary?\"  Both prompts returned SQL syntax, with the new prompt generating the more semantically correct query.\n",
        "* **Query:** \"Which institution has the highest average salary for employees with a PhD?\"  The old prompt hallucinates, the new prompt return SQL.\n",
        "* **Query:** \"What is the total salary of employees hired after 2015 who have a master's degree from 'MIT'?\"  The new prompt was more successful in handling this query, generating a logically sound query which the old prompt failed to do.\n",
        "* **Query:** (Most Complex Query) Both methods failed to handle the complex query correctly. The new prompt returned more reasonable SQL, albeit still incomplete.\n",
        "\n",
        "\n",
        "This evaluation demonstrates that structured and detailed prompting, particularly in conjunction with few-shot examples, significantly improves the accuracy and efficiency of GPT-3.5-turbo for tasks like NL2SQL conversion."
      ],
      "metadata": {
        "id": "Pj-jP5g6LqpB"
      },
      "id": "Pj-jP5g6LqpB"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}